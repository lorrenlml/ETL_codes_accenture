{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import boto3\n",
    "from argparse import ArgumentParser\n",
    "from datetime import datetime\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] -env STRING\n",
      "ipykernel_launcher.py: error: the following arguments are required: -env\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lorenzo.martin\\Miniconda3\\envs\\aws_s3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3259: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "parser = ArgumentParser(description=\"Please provide your Inputs as -i InputFile -o OutPutFile -c ConfigFile\")\n",
    "parser.add_argument(\"-env\", dest=\"env\", required=True,    help=\"Provide S3 environment (prod or dev)\", metavar=\"STRING\")\n",
    "args = parser.parse_args()\n",
    "env = args.env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'env' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\lorenzo.martin\\OneDrive - Accenture\\Documents\\MyWORK\\3.4 ebcdic_to_ascii\\converter_positional_delimited\\positional_to_delimited_cascade.ipynb Cell 3'\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/lorenzo.martin/OneDrive%20-%20Accenture/Documents/MyWORK/3.4%20ebcdic_to_ascii/converter_positional_delimited/positional_to_delimited_cascade.ipynb#ch0000002?line=2'>3</a>\u001b[0m BUCKET_NAME_DEV_REPORT \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mbucket-wz-aw-dev-euc-logs\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/lorenzo.martin/OneDrive%20-%20Accenture/Documents/MyWORK/3.4%20ebcdic_to_ascii/converter_positional_delimited/positional_to_delimited_cascade.ipynb#ch0000002?line=3'>4</a>\u001b[0m BUCKET_NAME_PROD_REPORT \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mbucket-wz-aw-prod-euc-logs\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/lorenzo.martin/OneDrive%20-%20Accenture/Documents/MyWORK/3.4%20ebcdic_to_ascii/converter_positional_delimited/positional_to_delimited_cascade.ipynb#ch0000002?line=5'>6</a>\u001b[0m \u001b[39mif\u001b[39;00m env \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mprod\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/lorenzo.martin/OneDrive%20-%20Accenture/Documents/MyWORK/3.4%20ebcdic_to_ascii/converter_positional_delimited/positional_to_delimited_cascade.ipynb#ch0000002?line=6'>7</a>\u001b[0m     bucket_name \u001b[39m=\u001b[39m BUCKET_NAME_PROD\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/lorenzo.martin/OneDrive%20-%20Accenture/Documents/MyWORK/3.4%20ebcdic_to_ascii/converter_positional_delimited/positional_to_delimited_cascade.ipynb#ch0000002?line=7'>8</a>\u001b[0m     bucket_name_report \u001b[39m=\u001b[39m BUCKET_NAME_PROD_REPORT\n",
      "\u001b[1;31mNameError\u001b[0m: name 'env' is not defined"
     ]
    }
   ],
   "source": [
    "BUCKET_NAME_DEV = 'bucket-wz-aw-dev-euc-data-ingestion'\n",
    "BUCKET_NAME_PROD = 'bucket-wz-aw-prod-euc-data-ingestion'\n",
    "BUCKET_NAME_DEV_REPORT = 'bucket-wz-aw-dev-euc-logs'\n",
    "BUCKET_NAME_PROD_REPORT = 'bucket-wz-aw-prod-euc-logs'\n",
    "\n",
    "if env == \"prod\":\n",
    "    bucket_name = BUCKET_NAME_PROD\n",
    "    bucket_name_report = BUCKET_NAME_PROD_REPORT\n",
    "elif env == \"dev\":\n",
    "    bucket_name = BUCKET_NAME_DEV\n",
    "    bucket_name_report = BUCKET_NAME_DEV_REPORT\n",
    "\n",
    "#bucket_name = 'bucket-wz-aw-dev-euc-data-ingestion'\n",
    "\n",
    "s3 = boto3.resource('s3')\n",
    "bucket = s3.Bucket(bucket_name)\n",
    "s3_client = boto3.client('s3')\n",
    "\n",
    "folder_input = 'positional/'  \n",
    "folder_output = 'delimited/'\n",
    "folder_report = 'report/'\n",
    "folder_schemas = 'interface-schema-field_length/'\n",
    "\n",
    "# create local folder if not exists\n",
    "\n",
    "if not os.path.exists(folder_input):\n",
    "    os.makedirs(folder_input)\n",
    "\n",
    "if not os.path.exists(folder_output):\n",
    "    os.makedirs(folder_output)\n",
    "\n",
    "if not os.path.exists(folder_report):\n",
    "    os.makedirs(folder_report)\n",
    "\n",
    "conversion_date = datetime.today().strftime('%Y-%m-%d')\n",
    "\n",
    "# report output folder in s3\n",
    "report = []\n",
    "report_columns = ['Conversion date', 'Input File', 'Interface', 'Status', 'Outcome', 'Solution', 'Responsible']\n",
    "report_file = '{}{}_delimited_converter_report.csv'.format(folder_report, conversion_date)\n",
    "folder_report_s3 = 'report_delimited/'\n",
    "report_file_s3 = '{}{}_delimited_converter_report.csv'.format(folder_report_s3, conversion_date)\n",
    "\n",
    "\n",
    "files = len(list(bucket.objects.filter(Prefix=folder_input))) -1\n",
    "print('FILES TO TRANSFORM:', files)\n",
    "\n",
    "for obj in tqdm(bucket.objects.filter(Prefix=folder_input)):\n",
    "    key = obj.key\n",
    "    if key != folder_input: #exclude folder object\n",
    "        \n",
    "        # download file from s3 to local\n",
    "        s3_client.download_file(bucket_name, key, key)\n",
    "        \n",
    "        # identify interface\n",
    "        if 'ODATE' in key:\n",
    "            interface = key.split('_')[2][7:12] \n",
    "        elif 'FDATE' in key:\n",
    "            interface = key.split('/')[1][7:12]\n",
    "        else:\n",
    "            report.append([conversion_date, key.split('/')[1], '', 'KO', 'Interface not identified in file name', 'Review file name', 'WiZink'])\n",
    "            print('Error: INFERFACE not found in file name {}'.format(key.split('/')[1]))\n",
    "            break\n",
    "\n",
    "        # select the schema-field_length.csv file for the interface      \n",
    "        file_list = os.listdir(folder_schemas)\n",
    "        for file in file_list:\n",
    "            if interface in file:\n",
    "                schema_file = file\n",
    "                break\n",
    "        else:\n",
    "            schema_file = ''\n",
    "\n",
    "        # delimit the input file if schema-field_length.csv exists\n",
    "        if schema_file != '':\n",
    "\n",
    "            # define output delimited file name\n",
    "            key_output = key.replace(folder_input, folder_output) + '_delimited.txt'\n",
    "            \n",
    "            os.system(\"python ConvertFixedToDelimiter.py -i {key} -o {key_output} -c {schema_file}\".format(key = key,\n",
    "                                                                                                        key_output = key_output, \n",
    "                                                                                                        schema_file = folder_schemas + schema_file))\n",
    "            \n",
    "            # upload file to s3\n",
    "            s3_client.upload_file(key_output, bucket_name, key_output)\n",
    "            report.append([conversion_date, key.split('/')[1], '{}'.format(interface), 'OK', 'Delimited file uploaded to /delimited','',''])\n",
    "\n",
    "            os.remove(key_output)\n",
    "        \n",
    "        else:\n",
    "            # if no schema file found, add to report\n",
    "            report.append([conversion_date, key.split('/')[1], '{}'.format(interface), 'KO', 'Schema file not found', 'Review schema files', 'Accenture'])\n",
    "            print('Error: SCHEMA FILE not found for interface ' + interface)\n",
    "    \n",
    "        # delete positional file\n",
    "        os.remove(key)\n",
    "\n",
    "# create report file\n",
    "with open(report_file, 'w') as f:\n",
    "    f.write('|'.join(report_columns) + '\\n')\n",
    "    for row in report:\n",
    "        f.write('|'.join(row) + '\\n')\n",
    "\n",
    "s3_client.upload_file(report_file, bucket_name_report, report_file_s3)\n",
    "print('Report file uploaded to S3 folder:', folder_report_s3)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2bdae6fe4e74c213dbbabb20f594c2125718203d4b4152af825fac47711826f8"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('aws_s3')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
